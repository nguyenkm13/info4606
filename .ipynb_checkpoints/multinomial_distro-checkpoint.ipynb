{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# generative models can generate data. Here is a very simple data generating function with one Bernoulli parameter P\n",
    "def generatePoint(p):\n",
    "    \n",
    "    if (random.random() < p):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "p = .5\n",
    "\n",
    "data = []\n",
    "\n",
    "for i in range(10):\n",
    "    data.append(generatePoint(0.5))\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "If you vary $p$ what do you observe about your generated data?\n",
    "\n",
    "$p$ closer to 1 results in more ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning\n",
    "\n",
    "Usually you don't know the parameters of your distribution when you start. You just have data. Let's generate some data with an \"unknown\" p, meaning it is \"hidden\" in a Python variable. We just won't peek at the variable. This is what things are like in the real world. You just have data; you don't know how it was generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_p_from_nature = random.random()\n",
    "\n",
    "data_in_the_world = []\n",
    "\n",
    "for i in range(10):\n",
    "    data_in_the_world.append(generatePoint(secret_p_from_nature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 1, 0, 1, 1, 1, 0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_in_the_world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "What do you think `secret_p_from_nature` is? Try to guess the value based on `data_in_the_world`. But don't peek!!\n",
    "\n",
    "0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning 2\n",
    "\n",
    "How can we systematically decide what parameter do we think generated the data? To answer we again use the \"[likelihood function](https://en.wikipedia.org/wiki/Likelihood_function)\". You have already seen the likelihood function when we studied logistic regression. The likelihood function returns the probability of the data $X$ given the parameters $\\theta$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write the likelihood function as $\\mathcal{L}(\\theta | X) = p_{\\theta}(X)$ where $\\theta$ is your parameters. \n",
    "\n",
    "- You should read this as: if the parameters are $\\theta$ what is the probability of our data? \n",
    "- Here $\\theta$ = $p$.\n",
    "- Notice that the likelihood function is a function of $\\theta$.\n",
    "\n",
    "### Question\n",
    "\n",
    "The likelihood function is a function. Functions in general map inputs to outputs.\n",
    "\n",
    "- What is the input to the function?\n",
    "- What is the output?\n",
    "\n",
    "\n",
    "The input is $\\theta$ and the output is the probability that we see the data $X$ with the given parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the likelihood\n",
    "\n",
    "So far we have talked about the likelihood as an abstraction. But what is $p_{\\theta}(X)$? \n",
    "\n",
    "This is something that *we* specify as the practitioner. When you make a generative model you are observing some data from nature and claiming that the data was generated in a particular way. You are making a claim about the process that generated the data. That process has parameters $\\theta$. The process + the parameters give you the likelihood. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Defining the likelihood 2\n",
    "\n",
    "For our case, let's say the data was generated from a Bernoulli distribution. A [Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution) defines the probability of a binary event, which can be thought of as a yes or no. For instance, you might use a Bernoulli distribution to model the probability that yes a coin lands on heads. The Bernoulli distribution has one parameter $p$.\n",
    "\n",
    "According to the Bernoulli distribution, the probability of a datapoint $x_i$ given $p$ is \n",
    "\\begin{equation}\n",
    "f(x_i;p) = \n",
    "\\begin{cases} \n",
    "p & \\text{if } x_i=1 \\\\\n",
    "q=1-p         & \\text{if } x_i=0\n",
    "\\end{cases}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BernoulliProbOnePoint(p, x_i):\n",
    "    '''\n",
    "    return the probability of x_i, according to the Bernoulli distribution with parameter p\n",
    "    '''\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
